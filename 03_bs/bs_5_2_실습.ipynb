{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 4~7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 실습 04. \n",
    "\n",
    "[문제] \\\n",
    "사이트내에 인기검색종목과 주요해외지수를 각각 크롤링하여 종목명과 주가지수를 아래와 같이 리스트로 정리해주세요. \\\n",
    "\\\n",
    "\\\n",
    "[결과]\n",
    "- 인기검색종목 \\\n",
    "[['써니전자', '5,000'], ['삼성전자', '55,200'], ['안랩', '81,000'], ['케이엠더블..', '57,300'], ['피피아이', '12,600’], \\\n",
    "['KT&G', '92,500'], ['삼성전자우', '45,600'], ['대양금속', '10,550'], ['SK하이닉스', '94,700'], ['SK텔레콤', '234,000’]]\n",
    "\n",
    "- 주요해외지수 \\\n",
    "[['다우산업', '28,647.43'], ['나스닥', '9,015.03'], ['홍콩H', '11,320.56'], ['상해종합', '3,085.20'], ['니케이225', '23,656.62']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "써니전자\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5,000\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "th_list = soup.select_one('a').get_text()\n",
    "print(th_list)\n",
    "\n",
    "print('------'*30)\n",
    "\n",
    "price = soup.find('span').get_text()\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['써니전자', '5,000'], ['삼성전자', '55,200'], ['안랩', '81,000'], ['케이엠더블..', '57,300'], ['피피아이', '12,600'], ['KT&G', '92,500'], ['삼성전자우', '45,600'], ['대양금속', '10,550'], ['SK하이닉스', '94,700'], ['SK텔레콤', '234,000']]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 인기 검색 종목\n",
    "popular_tags = soup.select('ul.lst_pop>li')\n",
    "\n",
    "popular_list = []\n",
    "for li_tag in popular_tags:\n",
    "    name = li_tag.select_one('a').text\n",
    "    price = li_tag.select_one('span').text\n",
    "\n",
    "    popular_list.append([name,price])\n",
    "\n",
    "\n",
    "print(popular_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[['다우산업', '28,647.43'], ['나스닥', '9,015.03'], ['홍콩H', '11,320.56'], ['상해종합', '3,085.20'], ['니케이225', '23,656.62']]\n"
     ]
    }
   ],
   "source": [
    "# 주요 해외 지수\n",
    "\n",
    "major_tags = soup.select('ul.lst_major > li')\n",
    "major_list =[]\n",
    "for li_tag in major_tags:\n",
    "    name = li_tag.select_one('a').text\n",
    "    price = li_tag.select_one('span').text\n",
    "\n",
    "    major_list.append([name,price])\n",
    "\n",
    "print(len(major_list))\n",
    "print(major_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 실습 05. \n",
    "\n",
    "[문제] \\\n",
    "사이트내에 인기검색종목과 주요해외지수를 각각 크롤링하여 종목명과 상한, 하한 여부를 아래와 같이 리스트로 정리해주세요. \\\n",
    "\\\n",
    "\\\n",
    "[결과] \n",
    "\n",
    "- 인기검색종목 \\\n",
    "[['써니전자', '상한'], ['삼성전자', '하한'], ['안랩', '상한'], ['케이엠더블..', '상한'], ['피피아이', '상한’], \\\n",
    "['KT&G', '하한'], ['삼성전자우', '상한'], \\['대양금속', '하한'], ['SK하이닉스', '상한'], ['SK텔레콤', '하한’]] \n",
    "\n",
    "- 주요해외지수 \\\n",
    "[['다우산업', '상한'], ['나스닥', '상한'], ['홍콩H', '상한'], ['상해종합', '상한'], ['니케이225', '하한']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[['써니전자', '상한'], ['삼성전자', '하락'], ['안랩', '상승'], ['케이엠더블..', '상승'], ['피피아이', '상한'], ['KT&G', '하락'], ['삼성전자우', '상승'], ['대양금속', '하한'], ['SK하이닉스', '상승'], ['SK텔레콤', '하락']]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[['다우산업', '28,647.43'], ['나스닥', '9,015.03'], ['홍콩H', '11,320.56'], ['상해종합', '3,085.20'], ['니케이225', '23,656.62'], ['다우산업', '상한'], ['나스닥', '상한'], ['홍콩H', '상한'], ['상해종합', '상한'], ['니케이225', '하락'], ['다우산업', '상한'], ['나스닥', '상한'], ['홍콩H', '상한'], ['상해종합', '상한'], ['니케이225', '하락']]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 인기 검색 종목\n",
    "popular_tags = soup.select('#popularItemList > li')\n",
    "\n",
    "popular_list= []\n",
    "for tag in popular_tags:\n",
    "    name= tag.select_one('a').get_text()\n",
    "    up_down=tag.select_one('img').attrs['alt']\n",
    "    \n",
    "    popular_list.append([name,up_down])\n",
    "\n",
    "print(len(popular_list))\n",
    "print(popular_list)\n",
    "\n",
    "print('------'*30)\n",
    "# 주요 해외지수\n",
    "\n",
    "major_tags = soup.select('.lst_major > li')\n",
    "mojor_list = []\n",
    "for tag in major_tags:\n",
    "\n",
    "    name = tag.select_one('a').text\n",
    "    up_down = tag.select_one('img').attrs['alt']\n",
    "\n",
    "    major_list.append([name,up_down])\n",
    "\n",
    "print(major_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 실습 06. \n",
    "\n",
    "[문제] \\\n",
    "사이트내에 인기검색종목과 주요해외지수를 각각 상한가인 종목만 크롤링하여 종목명과 주가지수를 아래와 같이 리스트로 정리해주세요.\n",
    "\n",
    "\n",
    "[결과]\n",
    "\n",
    "- 인기검색종목 \\\n",
    "[['써니전자', '5,000'], ['안랩', '81,000'], ['케이엠더블..', '57,300'], ['피피아이', '12,600’], ['삼성전자우', '45,600'], ['SK하이닉스', '94,700’]]\n",
    "\n",
    "- 주요해외지수 \\\n",
    "[['다우산업', '28,647.43'], ['나스닥', '9,015.03'], ['홍콩H', '11,320.56'], ['상해종합', '3,085.20']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['니케이225', '23,656.62'], ['니케이225', '23,656.62'], ['니케이225', '23,656.62'], ['니케이225', '23,656.62'], ['니케이225', '23,656.62'], ['니케이225', '23,656.62']]\n",
      "[['다우산업', '28,647.43'], ['나스닥', '9,015.03'], ['홍콩H', '11,320.56'], ['상해종합', '3,085.20'], ['니케이225', '23,656.62'], ['다우산업', '상한'], ['나스닥', '상한'], ['홍콩H', '상한'], ['상해종합', '상한'], ['니케이225', '하락'], ['다우산업', '상한'], ['나스닥', '상한'], ['홍콩H', '상한'], ['상해종합', '상한'], ['니케이225', '하락'], ['다우산업', '상한'], ['나스닥', '상한'], ['홍콩H', '상한'], ['상해종합', '상한']]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 인기 검색 종목\n",
    "popular_tags = soup.select('#popularItemList > li')\n",
    "popular_list = []\n",
    "\n",
    "for tag in popular_tags:\n",
    "    if ( tag.select_one('img').attrs['alt'] == '상한' ) or (tag.select_one('img').attrs['alt']=='상승'):\n",
    "        name = li_tag.select_one('a').text\n",
    "        price = li_tag.select_one('span').text\n",
    "\n",
    "        popular_list.append([name,price])\n",
    "    continue\n",
    "\n",
    "print(popular_list)\n",
    "\n",
    "# 주요 해외지수\n",
    "\n",
    "major_tags = soup.select('.lst_major > li')\n",
    "mojor_list = []\n",
    "for tag in major_tags:\n",
    "\n",
    "    if(tag.select_one('img').attrs['alt'] == '상한' ) or (tag.select_one('img').attrs['alt']=='상승'):\n",
    "        name = tag.select_one('a').text\n",
    "        up_down = tag.select_one('img').attrs['alt']\n",
    "\n",
    "        major_list.append([name,up_down])\n",
    "\n",
    "print(major_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 실습 07. \n",
    "\n",
    "[문제] \\\n",
    "분양중인 아파트 정보를 크롤링하여 아래와 같이 딕셔너리 형태로 정리 해주세요.\n",
    "- key : 이름, 보증금, 유형, 분양유형, 세대수, 평형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'이름': 'H하우스장위', '보증금': '16,000 만원', '유형': '16,000', '분양유형': '장기전세주택', '세대수': '분양 1세대', '평형': '16,000'}\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "name = soup.select_one('.sale_tit>a').get_text()\n",
    "price = soup.select_one('.txt').get_text()\n",
    "type_ = soup.select_one('strong').get_text()\n",
    "sale_type =li_tag.select('div.sale_detail dd.txt')[1].text.split('|')[1].strip()\n",
    "household = li_tag.select('div.sale_detail dd.txt')[2].text.split('|')[0].strip()\n",
    "space = li_tag.select('div.sale_detail dd.txt')[2].text.split('|')[1].strip()\n",
    "    \n",
    "\n",
    "\n",
    "result = {'이름':name, '보증금': price  , '유형': type_ , '분양유형': sale_type , '세대수': household  ,'평형':  type_ }\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'이름': 'H하우스장위', '보증금': '16,000', '유형': '아파트', '분양유형': '일반민간임대', '세대수': '분양 134세대', '평형': '45㎡~65㎡'}, {'이름': '고덕리엔파크2단지 장기전세', '보증금': '38,400', '유형': '아파트', '분양유형': '장기전세주택', '세대수': '분양 1세대', '평형': '149㎡'}, {'이름': '신정이펜하우스3단지 장기전세', '보증금': '39,040', '유형': '아파트', '분양유형': '장기전세주택', '세대수': '분양 1세대', '평형': '148㎡'}, {'이름': '천왕이펜하우스2단지 장기전세', '보증금': '38,240', '유형': '아파트', '분양유형': '장기전세주택', '세대수': '분양 1세대', '평형': '142㎡'}, {'이름': '송파파크데일2단지 장기전세', '보증금': '45,600', '유형': '아파트', '분양유형': '장기전세주택', '세대수': '분양 1세대', '평형': '150㎡'}]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "sale_list = ㄴ\n",
    "\n",
    "result = []\n",
    "for bgg in sale_list:\n",
    "    name = bgg.select_one('a').text.strip()\n",
    "    price = bgg.select_one('div.sale_detail dd.txt strong').text.strip()\n",
    "    type_=bgg.select('div.sale_detail dd.txt')[1].text.split('|')[0].strip()\n",
    "    sale_type = bgg.select('div.sale_detail dd.txt')[1].text.split('|')[1].strip()\n",
    "    household = bgg.select('div.sale_detail dd.txt')[2].text.split('|')[0].strip()\n",
    "    space = bgg.select('div.sale_detail dd.txt')[2].text.split('|')[1].strip()\n",
    "    \n",
    "    \n",
    "   # print(name,price,type_,sale_type,household,space)\n",
    "\n",
    "    result.append(dict(\n",
    "        이름=name,\n",
    "        보증금=price,\n",
    "        유형=type_,\n",
    "        분양유형=sale_type,\n",
    "        세대수=household,\n",
    "        평형=space\n",
    "    ))\n",
    "   \n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
