{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 1~3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 01. \n",
    "[문제]\\\n",
    "HTML문서 내에 ID가 cook인 태그의 내용을 출력해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전통적인 요리법이나 양식은 상당한 차이가 있지만, 이탈리아 요리는 다른 국가의 요리 문화에서 다양한 영감을 줄 만큼 다양하고 혁신적인 것으로 평가되고 있다. 각 지방마다 고유의 특색이 있어 그 양식도 다양하지만 크게 북부와 남부로 나눌 수 있다. 다른 나라와 국경을 맞대고 있던 북부 지방은 산업화되어 경제적으로 풍족하고 농업이 발달해 쌀이 풍부해 유제품이 다양한 반면 경제적으로 침체되었던 남부 지방은 올리브와 토마토, 모차렐라 치즈가 유명하고 특별히 해산물을 활용한 요리가 많다. 식재료와 치즈 등의 차이는 파스타의 종류와 소스와 수프 등도 다름을 의미한다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/01/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "cook_tag = soup.find(id='cook')\n",
    "print(cook_tag.text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 실습 02. \n",
    "[문제]\\\n",
    "HTML문서의 Table 내에 th와 td에 있는 값들을 크롤링해 아래와 같은 딕셔너리 형태를 만들어 보세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'이름': '이몽룡', '나이': '34'}, {'이름': '홍길동', '나이': '23'}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/01/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "th_tag = soup.select('table th')\n",
    "td_tag = soup.select('table td')\n",
    "th_tag.extend(th_tag)\n",
    "\n",
    "result = []\n",
    "dic = {}\n",
    "\n",
    "for th, td in zip(th_tag, td_tag):\n",
    "  \n",
    "  dic[th.text] = td.text\n",
    "\n",
    "  if th.text == '나이':\n",
    "    result.append(dic)\n",
    "    dic = {}\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr>\n",
      "<td>이몽룡</td>\n",
      "<td>34</td>\n",
      "</tr>, <tr>\n",
      "<td>홍길동</td>\n",
      "<td>23</td>\n",
      "</tr>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'이름': '이몽룡', '나이': '34'}, {'이름': '홍길동', '나이': '23'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/01/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "th_list = soup.select('thead th')\n",
    "\n",
    "keys = []\n",
    "for tag in th_list:\n",
    "    keys.append(tag.text)\n",
    "\n",
    "# print(keys)\n",
    "\n",
    "#--------------------- value 값 리스트에 담기 ---------------------------\n",
    "tr_list = soup.select('tbody tr')\n",
    "print(tr_list)\n",
    "\n",
    "result=[]\n",
    "for tr in tr_list:\n",
    "    values = []\n",
    "\n",
    "    for td in tr.select('td'):\n",
    "        values.append(td.text)\n",
    "        \n",
    "    result.append(dict(zip(keys, values)))\n",
    "\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 03. \n",
    "\n",
    "[문제] \\\n",
    "HTML문서 내에 모든 A태그에 링크된 페이지에 있는 내용을 읽어 출력해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01.html', '02.html', '03.html', '04.html']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  모든 a태그의 href속성 값 들고 오기\n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/01/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "urls = []\n",
    "for tag in soup.select('a'):\n",
    "    urls.append(tag.attrs['href'])\n",
    "\n",
    "\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링 연습사이트 01-1 페이지입니다.\n",
      "크롤링 연습사이트 01-2 페이지입니다.\n",
      "크롤링 연습사이트 01-3 페이지입니다.\n",
      "크롤링 연습사이트 01-4 페이지입니다.\n"
     ]
    }
   ],
   "source": [
    "# url 바꿔가며 p태그의 내용 들고 오기\n",
    "\n",
    "for url in urls:\n",
    "    res = requests.get('https://crawlingstudy-dd3c9.web.app/01/' + url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    text = soup.select_one('p').text.strip()\n",
    "    print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
